{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of R7_InternalLab_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PCcf1xZKOi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "import numpy as np# Note you only need to define the input data shape with the first layer. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "((trainX, trainY), (testX, testY))  = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "outputId": "424f6ef1-d058-4888-e547-f1263a186304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zewyDcBlJjv1",
        "colab_type": "code",
        "outputId": "69f7b897-f295-4fa1-c7f8-cc0d61ff86bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycQGBSGJjv5",
        "colab_type": "code",
        "outputId": "f1c77053-403d-4793-9b74-1be46bcc36fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "outputId": "866e69c1-ae9e-41ad-997f-d7acce239e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.unique(trainY)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHSCXy3JjwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY=np_utils.to_categorical(trainY,10)\n",
        "testY=np_utils.to_categorical(testY,10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX =trainX/255\n",
        "testX= testX/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okwo_SB5JjwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX=trainX.reshape(trainX.shape[0],28,28,1).astype('float32')    # The digit 1 signifies the images are in grayscale\n",
        "testX=testX.reshape(testX.shape[0],28,28,1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# The last layers is a dense layer with softmax activation that classifies the 10 categories of data in fashion_mnist.\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORCLgSwJjwV",
        "colab_type": "code",
        "outputId": "5b7a4a91-a53e-44fd-e86a-b91465b8f93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='valid', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='valid', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "# Take a look at the model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               2359424   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,370,282\n",
            "Trainable params: 2,370,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShcvQlb3PTsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_76UzuVRxkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]# [stats, early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6vrAOt4PYMJ",
        "colab_type": "code",
        "outputId": "29f762d5-0496-4878-b380-e7afa14552c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "model.fit(trainX, trainY ,batch_size=64,nb_epoch=10,verbose=1,validation_data=(testX, testY),callbacks=callback_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.4967 - acc: 0.8232 - val_loss: 0.3284 - val_acc: 0.8807\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3311 - acc: 0.8820 - val_loss: 0.2802 - val_acc: 0.8989\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2763 - acc: 0.8990 - val_loss: 0.2611 - val_acc: 0.9061\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2410 - acc: 0.9124 - val_loss: 0.2531 - val_acc: 0.9116\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2106 - acc: 0.9223 - val_loss: 0.2523 - val_acc: 0.9101\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1850 - acc: 0.9320 - val_loss: 0.2472 - val_acc: 0.9158\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1608 - acc: 0.9398 - val_loss: 0.2383 - val_acc: 0.9160\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1418 - acc: 0.9477 - val_loss: 0.2482 - val_acc: 0.9206\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1230 - acc: 0.9529 - val_loss: 0.2995 - val_acc: 0.9163\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1114 - acc: 0.9572 - val_loss: 0.2739 - val_acc: 0.9199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f503a1560f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "outputId": "9052ec3f-4467-41d7-a020-4586b4d9fa74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "model1 = tf.keras.Sequential()\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model1.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='valid', activation='relu', input_shape=(28,28,1))) \n",
        "model1.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='valid', activation='relu', input_shape=(28,28,1))) \n",
        "model1.add(tf.keras.layers.MaxPooling2D(pool_size=2 , padding='valid'))\n",
        "model1.add(tf.keras.layers.Dropout(0.25))\n",
        "model1.add(tf.keras.layers.Flatten())\n",
        "model1.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model1.add(tf.keras.layers.Dropout(0.5))\n",
        "model1.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "# Take a look at the model summary\n",
        "model1.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 600,810\n",
            "Trainable params: 600,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoH8Vq2RVZHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjiWBap3VdMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]# [stats, early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCMmtOuiViU7",
        "colab_type": "code",
        "outputId": "ae1d5dc1-f075-4d5c-fbb9-cc52014d4d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "model1.fit(trainX, trainY ,batch_size=64,nb_epoch=10,verbose=1,validation_data=(testX, testY),callbacks=callback_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.5062 - acc: 0.8214 - val_loss: 0.3336 - val_acc: 0.8773\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3392 - acc: 0.8791 - val_loss: 0.2831 - val_acc: 0.8958\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2881 - acc: 0.8945 - val_loss: 0.2554 - val_acc: 0.9036\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2630 - acc: 0.9046 - val_loss: 0.2486 - val_acc: 0.9082\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2412 - acc: 0.9115 - val_loss: 0.2360 - val_acc: 0.9104\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2228 - acc: 0.9185 - val_loss: 0.2268 - val_acc: 0.9181\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2082 - acc: 0.9233 - val_loss: 0.2224 - val_acc: 0.9168\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1935 - acc: 0.9275 - val_loss: 0.2303 - val_acc: 0.9170\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1834 - acc: 0.9315 - val_loss: 0.2119 - val_acc: 0.9239\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1724 - acc: 0.9349 - val_loss: 0.2273 - val_acc: 0.9213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f50077959b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "\tfeaturewise_center=False,\n",
        "\tsamplewise_center=False,\n",
        "\tfeaturewise_std_normalization=False,\n",
        "\tsamplewise_std_normalization=False,\n",
        "\tzca_whitening=False,\n",
        "\trotation_range=50,\n",
        "\twidth_shift_range=0.1,\n",
        "\theight_shift_range=0.1,\n",
        "\thorizontal_flip=False,\n",
        "\tvertical_flip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV0MX70tavHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "outputId": "7281e76e-3c21-46fe-ef1c-38cdb90e598c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(trainX[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOWqXV-Aem7L",
        "colab_type": "code",
        "outputId": "5183e0cc-b1a3-42be-fa09-94bc49e583c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "outputId": "f2f03677-81bd-434e-e190-149e1f6e66dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "model1.fit_generator(datagen.flow(trainX,trainY, batch_size=32), validation_data=(testX, testY),steps_per_epoch=len(trainX) / 32, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.8386 - acc: 0.6923 - val_loss: 0.3705 - val_acc: 0.8718\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6600 - acc: 0.7566 - val_loss: 0.3686 - val_acc: 0.8653\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6081 - acc: 0.7753 - val_loss: 0.3704 - val_acc: 0.8695\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5769 - acc: 0.7878 - val_loss: 0.3809 - val_acc: 0.8620\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5576 - acc: 0.7961 - val_loss: 0.3871 - val_acc: 0.8634\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5414 - acc: 0.7992 - val_loss: 0.3758 - val_acc: 0.8683\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5325 - acc: 0.8043 - val_loss: 0.3711 - val_acc: 0.8699\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5171 - acc: 0.8098 - val_loss: 0.4011 - val_acc: 0.8645\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5097 - acc: 0.8140 - val_loss: 0.3693 - val_acc: 0.8735\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5066 - acc: 0.8155 - val_loss: 0.3720 - val_acc: 0.8694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f503bdcef28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "outputId": "a34e155e-486a-4ae7-c65e-4603862ef265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model1.evaluate(testX, testY, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 86.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBwVWNQC2qZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simple CNN model for the CIFAR-10 Dataset\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6hicLwP4SqY",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Pht1ggHuiT",
        "colab_type": "code",
        "outputId": "9b1305d5-3de3-4351-9ab8-6f9bdb6765bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# normalize inputs from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "epochs = 40\n",
        "lrate = 0.01\n",
        "#decay = lrate/epochs\n",
        "          \n",
        "#sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'] , )\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_acc', patience=2, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]# [stats, early_stopping]\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32 , callbacks=callback_list)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 4,210,090\n",
            "Trainable params: 4,210,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "50000/50000 [==============================] - 15s 292us/step - loss: 1.4352 - acc: 0.4866 - val_loss: 1.1735 - val_acc: 0.6000\n",
            "Epoch 2/40\n",
            "50000/50000 [==============================] - 14s 275us/step - loss: 1.0824 - acc: 0.6196 - val_loss: 0.9757 - val_acc: 0.6609\n",
            "Epoch 3/40\n",
            "50000/50000 [==============================] - 14s 273us/step - loss: 0.9411 - acc: 0.6698 - val_loss: 0.9278 - val_acc: 0.6778\n",
            "Epoch 4/40\n",
            "50000/50000 [==============================] - 14s 273us/step - loss: 0.8433 - acc: 0.7024 - val_loss: 0.9121 - val_acc: 0.6852\n",
            "Epoch 5/40\n",
            "50000/50000 [==============================] - 14s 272us/step - loss: 0.7501 - acc: 0.7349 - val_loss: 0.8924 - val_acc: 0.6998\n",
            "Epoch 6/40\n",
            "50000/50000 [==============================] - 14s 274us/step - loss: 0.6697 - acc: 0.7624 - val_loss: 0.9510 - val_acc: 0.6847\n",
            "Epoch 7/40\n",
            "50000/50000 [==============================] - 14s 274us/step - loss: 0.6016 - acc: 0.7855 - val_loss: 0.9364 - val_acc: 0.6995\n",
            "Epoch 00007: early stopping\n",
            "Accuracy: 69.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n28ccU6Hp6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen1 = ImageDataGenerator(\n",
        "\tfeaturewise_center=False,\n",
        "\tsamplewise_center=False,\n",
        "\tfeaturewise_std_normalization=False,\n",
        "\tsamplewise_std_normalization=False,\n",
        "\tzca_whitening=False,\n",
        "\trotation_range=50,\n",
        "\twidth_shift_range=0.5,\n",
        "\theight_shift_range=0.6,\n",
        "\thorizontal_flip=True,\n",
        "\tvertical_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSw8Bv2_4hb0",
        "colab_type": "code",
        "outputId": "adb5e037-5d6a-4651-d9ee-4fd0f48390bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "model.fit_generator(datagen1.flow(X_train, y_train, batch_size=32), validation_data=(X_test, y_test),steps_per_epoch=len(X_train) / 32, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1562 [==============================] - 26s 17ms/step - loss: 1.9955 - acc: 0.2661 - val_loss: 1.5635 - val_acc: 0.4486\n",
            "Epoch 2/10\n",
            "1563/1562 [==============================] - 26s 16ms/step - loss: 1.8866 - acc: 0.3042 - val_loss: 1.5932 - val_acc: 0.4369\n",
            "Epoch 3/10\n",
            "1563/1562 [==============================] - 26s 16ms/step - loss: 1.8429 - acc: 0.3206 - val_loss: 1.5055 - val_acc: 0.4647\n",
            "Epoch 4/10\n",
            "1563/1562 [==============================] - 26s 17ms/step - loss: 1.8185 - acc: 0.3333 - val_loss: 1.4982 - val_acc: 0.4660\n",
            "Epoch 5/10\n",
            "1563/1562 [==============================] - 26s 17ms/step - loss: 1.8016 - acc: 0.3414 - val_loss: 1.5153 - val_acc: 0.4550\n",
            "Epoch 6/10\n",
            "1563/1562 [==============================] - 26s 17ms/step - loss: 1.7886 - acc: 0.3473 - val_loss: 1.5154 - val_acc: 0.4568\n",
            "Epoch 7/10\n",
            "1563/1562 [==============================] - 26s 17ms/step - loss: 1.7688 - acc: 0.3534 - val_loss: 1.4744 - val_acc: 0.4692\n",
            "Epoch 8/10\n",
            "1563/1562 [==============================] - 26s 17ms/step - loss: 1.7610 - acc: 0.3586 - val_loss: 1.5051 - val_acc: 0.4662\n",
            "Epoch 9/10\n",
            "1563/1562 [==============================] - 26s 17ms/step - loss: 1.7550 - acc: 0.3580 - val_loss: 1.4876 - val_acc: 0.4611\n",
            "Epoch 10/10\n",
            "1563/1562 [==============================] - 26s 17ms/step - loss: 1.7480 - acc: 0.3630 - val_loss: 1.5501 - val_acc: 0.4368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f503b1bd6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f4d1904f-f669-42ec-dc74-a2a39126893e",
        "id": "tuEsu98QmZjY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 43.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXug4z234mwQ",
        "colab_type": "code",
        "outputId": "37340962-a27b-4bc5-bb11-13a7c1e5d6b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen1.flow(X_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABcCAYAAAB3AO7GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncAsLC4trCtuBW1hYWFxT/H8a4iM3hTA+5gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}